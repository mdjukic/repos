# Staging to DW table approach

##Requirement

Review different approaches to move data from the staging tables to DW tables (also in Redshift)

##Considered
* UDFs
* Lambda
* Postgres FDW
* Native scripts

It seems that many people have looked at the issue of transforming data within Redshift without really reaching reaching much of a consensus.
Lots of tools out there but it's another layer. 

###UDFs
UDFs in Redshift are scalar only so are not able to provide the functionality required to move the data from A->B. We may however use them as part 
of the solution as required. Not a solution in itself.

###Lambda functions
The process to load the files is already performed in Lambda functions, so logically it makes sense to perform the downstream processing 
using the same method. As to producing the data, it all moves within the Redshift instance so it is logical to perform this task within SQL. 
The Lambda function will provide the wrapper and control structure around it, handling the logging.

###Postgres FDW
This provides the more attractive solution as it's a more straightforward port from the code already developed in SQL Server and permits the use
of stored procedures and thus a logical way to encaspsulate the functionality, error handling etc.

The downside to using this method is that it places the functionality in another location and creates a dependency between the data warehouse 
and another Postgres database. This has an impact on the portability and scalability of the solution. Particularly if further down the line a
decision is made to switch to another platform. For this reason this is not the preferred solution.

###Native scripts
Using native SQL scripts with variables substituted at runtime we can replicate much of the funtionality of stored procedures within the Redshift 
world. There will be some complexities around error handling that we will need to investigate further. The proposal is that we generate a script
(or series of scripts) per load function. These scripts will initially be held in files in S3 buckets - this solution may evolve to host these 
in a database. Or maybe one bright day Redshift will grow to support stored procs.

Following discussion with Stuart and Matt, this is the preferred solution.


##TL;DR
The preferred approach is to develop one or more sql scripts per transformation. These scripts will be called by a python process run inside 
a lambda function. We also use the lambda functions to pick up and load the input files, so the architecture is consistent at least.